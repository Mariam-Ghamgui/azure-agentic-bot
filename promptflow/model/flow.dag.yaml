$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
display_name: M2C Bot Chat Flow
description: Azure AI Foundry Prompt Flow for the m2c-bot project.

inputs:
  chat_history:
    type: list
    is_chat_input: false
    is_chat_history: true
  question:
    type: string
    is_chat_input: true
  SUBSCRIPTION_ID:
    type: string
    default: ""
    is_chat_input: false
  TENANT_ID:
    type: string
    default: ""
    is_chat_input: false
  CLIENT_SECRET:
    type: string
    default: ""
    is_chat_input: false
  CLIENT_ID:
    type: string
    default: ""
    is_chat_input: false
  "":
    type: string
    default: ""
    is_chat_input: false

outputs:
  answer:
    type: string
    reference: ${response.output}
    is_chat_output: true

nodes:
- name: trigger
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: ${aoaiDeploymentName} 
    temperature: 0.7
    top_p: 1
    max_tokens: 256
    response_format:
      type: json_object
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
    subscriptionId: ${inputs.SUBSCRIPTION_ID}
  provider: AzureOpenAI
  connection: ${aoaiConnectionName}
  api: chat
  module: promptflow.tools.aoai
  use_variants: false

- name: task
  type: python
  source:
    type: code
    path: task.py
  inputs:
    clientId: ${inputs.CLIENT_ID}
    clientSecret: ${inputs.CLIENT_SECRET}
    input1: ${trigger.output}
    subscriptionId: ${inputs.SUBSCRIPTION_ID}
    tenantId: ${inputs.TENANT_ID}
  use_variants: false

- name: response
  type: llm
  source:
    type: code
    path: response.jinja2
  inputs:
    deployment_name: ${aoaiDeploymentName}
    temperature: 0.7
    top_p: 1
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
    task: ${task.output}
  provider: AzureOpenAI
  connection: ${aoaiConnectionName}
  api: chat
  module: promptflow.tools.aoai
  use_variants: false  
node_variants: {}

environment:
  python_requirements_txt: requirements.txt
